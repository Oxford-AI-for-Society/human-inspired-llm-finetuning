{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yushi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/yushi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yushi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/yushi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import random\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Within what time in the period of infectivity will an immunocompetent child display chickenpox signs after contacting an infectious patient (with chickenpox)?\n",
      "Augmented Text: Within what time in the period of infectivity will an immunocompetent nestling display varicella subscribe after contact an infectious patient_role ( with chickenpox ) ?\n"
     ]
    }
   ],
   "source": [
    "# Get the list of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_pos_tag(word):\n",
    "    return nltk.pos_tag([word])[0][1]\n",
    "\n",
    "def get_synonyms(word, pos_tag):\n",
    "    synonyms = []\n",
    "    if word.lower() in stop_words:\n",
    "        return []  # Return an empty list if the word is a stop word\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            lemma_name = lemma.name()\n",
    "            if lemma_name.lower() != word.lower() and lemma_name not in stop_words:  # Additional check for case-insensitive match\n",
    "                synonyms.append(lemma_name)\n",
    "    return list(set(synonyms))  # Return unique synonyms\n",
    "\n",
    "def replace_with_synonym(word, synonyms):\n",
    "    if synonyms:\n",
    "        return random.choice(synonyms)\n",
    "    return word\n",
    "\n",
    "def augment_with_synonyms(text, target_replacements):\n",
    "    sentences = sent_tokenize(text)\n",
    "    augmented_sentences = []\n",
    "    replacements = 0\n",
    "    words_processed = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokenized = word_tokenize(sentence)\n",
    "        replaceable_tokens = [token for token in tokenized if get_synonyms(token, get_pos_tag(token))]\n",
    "\n",
    "        words_to_replace = random.sample(replaceable_tokens, min(target_replacements - replacements, len(replaceable_tokens)))\n",
    "\n",
    "        augmented_tokens = []\n",
    "\n",
    "        for token in tokenized:\n",
    "            if replacements >= target_replacements:\n",
    "                augmented_tokens.append(token)\n",
    "                continue\n",
    "\n",
    "            if token in words_to_replace and token not in words_processed and token.lower() not in stop_words:\n",
    "                pos_tag = get_pos_tag(token)\n",
    "                synonyms = get_synonyms(token, pos_tag)\n",
    "                original_token = token\n",
    "                token = replace_with_synonym(token, synonyms)\n",
    "\n",
    "                if token != original_token:\n",
    "                    replacements += 1\n",
    "                    words_processed.append(original_token)\n",
    "\n",
    "            augmented_tokens.append(token)\n",
    "\n",
    "        augmented_sentence = ' '.join(augmented_tokens)\n",
    "        augmented_sentences.append(augmented_sentence)\n",
    "\n",
    "        if replacements >= target_replacements:\n",
    "            break\n",
    "\n",
    "    augmented_text = ' '.join(augmented_sentences)\n",
    "    return augmented_text\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "original_text = \"Within what time in the period of infectivity will an immunocompetent child display chickenpox signs after contacting an infectious patient (with chickenpox)?\"\n",
    "target_replacements = 5  # Maximum number of words to be replaced\n",
    "\n",
    "print(\"Original Text:\", original_text)\n",
    "augmented_text = augment_with_synonyms(original_text, target_replacements=target_replacements)\n",
    "print(f\"Augmented Text:\", augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/code/llm-fine-tuning/lek_augmented_150_syn_replaced_three_quarters.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('/code/llm-fine-tuning/lek_training_sets/lek_augmented_50_three_quarters.csv')\n",
    "\n",
    "# Apply the augmentation function to 'augmented' rows and remove the original 'augmented' rows\n",
    "df.loc[df['Data Type'] == 'augmented', 'Prompt'] = df[df['Data Type'] == 'augmented']['Prompt'].apply(lambda x: augment_with_synonyms(x, 5))\n",
    "\n",
    "# Save the modified dataframe\n",
    "output_file_path = '/code/llm-fine-tuning/lek_augmented_50_syn_replaced_three_quarters.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words in 'Prompt': 31.834096109839816\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Make sure to download the 'punkt' package with the following line:\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/code/llm-fine-tuning/lek_training_sets/lek_full_random.csv')\n",
    "\n",
    "# Calculate the average number of words in the 'Prompt' column\n",
    "df['word_count'] = df['Prompt'].apply(lambda x: len(word_tokenize(x)))\n",
    "average_word_count = df['word_count'].mean()\n",
    "\n",
    "print(\"Average number of words in 'Prompt':\", average_word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/code/llm-fine-tuning/lek_training_sets/lek_three_quarters_random.csv')\n",
    "\n",
    "# Define a function to modify the 'Answer' column\n",
    "def modify_answer(row):\n",
    "    answer_letter = row['Answer']\n",
    "    answer_text = row[answer_letter]\n",
    "    return f\"{answer_letter}) {answer_text}\"\n",
    "\n",
    "# Apply the function to each row\n",
    "df['Answer'] = df.apply(modify_answer, axis=1)\n",
    "\n",
    "# Save the modified dataset to a new file\n",
    "df.to_csv('/code/llm-fine-tuning/lek_training_sets/lek_three_quarters_random_long_answer.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autotrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
