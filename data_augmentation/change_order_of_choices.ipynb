{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/code/llm-fine-tuning/lek_training_sets/lek_three_quarters_random.csv'  # Update this with the actual file path\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords that indicate a row should not be augmented\n",
    "keywords = [\n",
    "    \"all the above.\", \"all of the above.\", \"none of the above\", \"none of the above.\", \n",
    "    \"answers A, B and C are correct.\", \"answers B and D are correct.\", \n",
    "    \"answers B and C are correct.\", \"B and C are true.\", \"A and C are true.\", \"A, B, C are true.\", \n",
    "    \"answers A and B are correct.\", \"A and B are true.\", \"A, B, and C are true.\", \n",
    "    \"A,B are true.\", \"answers A and C are correct.\", \"answers B and C are true.\", \n",
    "    \"A,B are correct.\", \"A, B, and C are true.\", \"A, B and C are true.\", \n",
    "    \"none of the above is correct.\", \"all of the above are true.\", \n",
    "    \"A and D are correct.\", \"answers A, B, C are correct.\", \"answers A, B and C are true.\", \n",
    "    \"answers A,B,C are correct.\", \"A, C and D are true.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset augmented and saved to /code/llm-fine-tuning/lek_augmented_three_quarters.csv.\n"
     ]
    }
   ],
   "source": [
    "# Function to check if any of the keywords are present in the 'D' or 'E' options\n",
    "def check_keywords(row):\n",
    "    d_option = row['D']\n",
    "    e_option = row['E']\n",
    "    for keyword in keywords:\n",
    "        if any(keyword == option for option in [d_option, e_option]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the function to identify rows to exclude\n",
    "data['exclude_for_augmentation'] = data.apply(check_keywords, axis=1)\n",
    "\n",
    "# Function to augment a row\n",
    "def augment_row(row):\n",
    "    options = ['A', 'B', 'C', 'D', 'E']\n",
    "    correct_answer = row['Answer']\n",
    "    original_options = [row[option] for option in options]\n",
    "    \n",
    "    # Randomly permute the options\n",
    "    permuted_options = random.sample(original_options, len(original_options))\n",
    "    \n",
    "    # Update the 'Answer' based on the new order of options\n",
    "    new_answer = chr(permuted_options.index(original_options[ord(correct_answer) - ord('A')]) + ord('A'))\n",
    "    \n",
    "    # Update the row with permuted options and new answer\n",
    "    for i, option in enumerate(options):\n",
    "        row[option] = permuted_options[i]\n",
    "    row['Answer'] = new_answer\n",
    "    row['Data Type'] = 'augmented'\n",
    "    return row\n",
    "\n",
    "# Filter rows that are not excluded and apply augmentation\n",
    "augmented_rows = data[~data['exclude_for_augmentation']].apply(augment_row, axis=1)\n",
    "\n",
    "# Mark original rows and prepare them for concatenation\n",
    "data['Data Type'] = 'original'\n",
    "data['Not Used For Augmentation'] = data['exclude_for_augmentation']\n",
    "\n",
    "# Concatenate original and augmented rows\n",
    "resulting_data = pd.concat([data, augmented_rows], ignore_index=True)\n",
    "\n",
    "# Drop the 'exclude_for_augmentation' column\n",
    "resulting_data.drop(columns=['exclude_for_augmentation'], inplace=True)\n",
    "\n",
    "# Save the resulting dataset to a CSV file\n",
    "augmented_file_path = '/code/llm-fine-tuning/lek_augmented_three_quarters.csv'  # Update this with your desired file path\n",
    "resulting_data.to_csv(augmented_file_path, index=False)\n",
    "\n",
    "print(f\"Dataset augmented and saved to {augmented_file_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autotrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
